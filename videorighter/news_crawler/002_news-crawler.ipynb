{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requests 패키지 가져오기\n",
    "import requests\n",
    "\n",
    "# 가져올 url 문자열로 입력\n",
    "url = 'https://s.search.naver.com/p/newssearch/search.naver?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, parse_qs, parse_qsl, urlencode, urlunparse\n",
    "from datetime import datetime\n",
    "\n",
    "params = {\n",
    "    'field': ['0'],\n",
    "    'is_dts': ['0'],\n",
    "    'is_sug_officeid': ['0'],\n",
    "    'mynews': ['0'],\n",
    "    'nqx_theme': ['{\"theme\":{\"main\":{\"name\":\"corporation_hq\"},\"sub\":[{\"name\":\"stock\"}]}}'],\n",
    "    'nso': ['&nso=so:dd,p:1h,a:all', 'so:dd,p:1h,a:all'],\n",
    "    'office_category': ['0'],\n",
    "    'office_section_code': ['0'],\n",
    "    'office_type': ['0'],\n",
    "    'photo': ['0'],\n",
    "    'query': ['삼성전자'],\n",
    "    'service_area': ['0'],\n",
    "    'sort': ['1'],\n",
    "    'spq': ['0'],\n",
    "    'start': ['11'],\n",
    "    'where': ['news_tab_api']\n",
    "}\n",
    "\n",
    "params['ds'] = ['2024.05.20.00.00']\n",
    "params['de'] = [datetime.now().strftime(\"%Y.%m.%d.%H.%M\")]\n",
    "params['sort'] = \"1\"\n",
    "params['start'] = \"1\"\n",
    "\n",
    "parts = urlparse(url)\n",
    "parts = parts._replace(query=urlencode(params, doseq=True))\n",
    "new_url = urlunparse(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s.search.naver.com/p/newssearch/search.naver?field=0&is_dts=0&is_sug_officeid=0&mynews=0&nqx_theme=%7B%22theme%22%3A%7B%22main%22%3A%7B%22name%22%3A%22corporation_hq%22%7D%2C%22sub%22%3A%5B%7B%22name%22%3A%22stock%22%7D%5D%7D%7D&nso=%26nso%3Dso%3Add%2Cp%3A1h%2Ca%3Aall&nso=so%3Add%2Cp%3A1h%2Ca%3Aall&office_category=0&office_section_code=0&office_type=0&photo=0&query=%EC%82%BC%EC%84%B1%EC%A0%84%EC%9E%90&service_area=0&sort=1&spq=0&start=1&where=news_tab_api&ds=2024.05.20.17.00&de=2024.05.20.18.17\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m total \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 21\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     soup \u001b[38;5;241m=\u001b[39m bs(response\u001b[38;5;241m.\u001b[39mcontent, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m     naver_news_links \u001b[38;5;241m=\u001b[39m [a[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, string\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m네이버뉴스\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m a[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[0;32m~/anaconda3/envs/ais/lib/python3.9/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ais/lib/python3.9/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ais/lib/python3.9/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/envs/ais/lib/python3.9/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/anaconda3/envs/ais/lib/python3.9/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/anaconda3/envs/ais/lib/python3.9/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    787\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    806\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ais/lib/python3.9/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/anaconda3/envs/ais/lib/python3.9/site-packages/urllib3/connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/anaconda3/envs/ais/lib/python3.9/http/client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1377\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1379\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/ais/lib/python3.9/http/client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ais/lib/python3.9/http/client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 281\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ais/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ais/lib/python3.9/ssl.py:1275\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1272\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1273\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1274\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/ais/lib/python3.9/ssl.py:1133\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "\n",
    "headers = {\n",
    "    # \"User-Agent\": generate_user_agent(os='win',device_type='desktop'),\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "params['ds'] = ['2024.05.20.17.00']\n",
    "params['de'] = [datetime.now().strftime(\"%Y.%m.%d.%H.%M\")]\n",
    "params['sort'] = \"1\"\n",
    "params['start'] = \"1\"\n",
    "parts = urlparse(url)\n",
    "parts = parts._replace(query=urlencode(params, doseq=True))\n",
    "new_url = urlunparse(parts)\n",
    "print(new_url)\n",
    "\n",
    "total = []\n",
    "\n",
    "while True:\n",
    "    response = requests.get(new_url)\n",
    "    soup = bs(response.content, 'html.parser')\n",
    "    naver_news_links = [a['href'] for a in soup.find_all('a', string='네이버뉴스') if a['href']]\n",
    "\n",
    "    for link in naver_news_links:\n",
    "        tmp = {}\n",
    "        article_res = requests.get(link[2:-2])\n",
    "        article_soup = bs(article_res.content, 'html.parser')\n",
    "        title = article_soup.select_one('#title_area > span').get_text(strip=True)\n",
    "        tmp['title'] = title\n",
    "        time = article_soup.select_one('#ct > div.media_end_head.go_trans > div.media_end_head_info.nv_notrans > div.media_end_head_info_datestamp > div:nth-child(1) > span')['data-date-time']\n",
    "        tmp['date_news'] = time\n",
    "        try:\n",
    "            summary = article_soup.select_one('#dic_area > strong').get_text(strip=True)\n",
    "        except AttributeError:\n",
    "            summary = None\n",
    "        tmp['summary'] = summary\n",
    "        for tag in article_soup.find_all(class_='end_photo_org'):\n",
    "            tag.decompose()\n",
    "        main = article_soup.select_one('#dic_area').get_text(strip=True).replace(\"\\n\\n\\n\", \"\")\n",
    "        tmp['content'] = main\n",
    "        tmp['date_collect'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        tmp['url'] = link[2:-2]\n",
    "\n",
    "        total.append(tmp)\n",
    "        if tmp in total:\n",
    "            break\n",
    "    params['de'] = [datetime.now().strftime(\"%Y.%m.%d.%H.%M\")]\n",
    "    params['start'] = str(int(params['start'])+10)\n",
    "    parts = parts._replace(query=urlencode(params, doseq=True))\n",
    "    new_url = urlunparse(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (249453642.py, line 29)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[35], line 29\u001b[0;36m\u001b[0m\n\u001b[0;31m    title_element = soup.find(\"div\").find(\"div\", \"class\": \"\\&quot;news_contents\\&quot;\")\u001b[0m\n\u001b[0m                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "from lxml import html\n",
    "\n",
    "\n",
    "headers = {\n",
    "    # \"User-Agent\": generate_user_agent(os='win',device_type='desktop'),\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "new_url = 'https://s.search.naver.com/p/newssearch/search.naver?cluster_rank=38&de=2024.05.27.18.03&ds=2024.05.27.15.03&eid=&field=0&force_original=&is_dts=0&is_sug_officeid=0&mynews=1&news_office_checked=&nlu_query=&nqx_theme=%7B%22theme%22%3A%7B%22main%22%3A%7B%22name%22%3A%22corporation_hq%22%7D%2C%22sub%22%3A%5B%7B%22name%22%3A%22issue%22%7D%2C%7B%22name%22%3A%22stock%22%7D%5D%7D%7D&nso=%26nso%3Dso%3Ar%2Cp%3Aall%2Ca%3Aall&nx_and_query=&nx_search_hlquery=&nx_search_query=&nx_sub_query=&office_category=0&office_section_code=0&office_type=0&pd=9&photo=0&query=%EC%82%BC%EC%84%B1%EC%A0%84%EC%9E%90&query_original=&service_area=0&sort=0&spq=3&start=21&where=news_tab_api&nso=so:r,p:all,a:all&_callback=jQuery1124036467539337756794_1716800613836&_=1716800613839'\n",
    "\n",
    "total = []\n",
    "\n",
    "# while True:\n",
    "response = requests.get(new_url, headers=headers)\n",
    "# Decode the content properly\n",
    "decoded_content = response.content.decode('utf-8')\n",
    "\n",
    "# Parse the HTML content\n",
    "tree = html.fromstring(decoded_content)\n",
    "li_elements = tree.xpath('//li')\n",
    "\n",
    "\n",
    "for index, li in enumerate(li_elements, start=1):\n",
    "    string = html.tostring(li, pretty_print=True, encoding='unicode')\n",
    "    soup = bs(string, 'html.parser')\n",
    "    title_element = soup.find(\"div\").find(\"div\", \"class\": \"\\&quot;news_contents\\&quot;\")\n",
    "    print(title_element)\n",
    "    content_element = soup.find(class_=\"\\&quot;api_txt_lines\")\n",
    "\n",
    "    title = title_element.text.strip() if title_element else \"No title found\"\n",
    "    content = content_element.text.strip() if content_element else \"No content found\"\n",
    "\n",
    "    print(f\"Element {index}:\")\n",
    "    print(f\"Title: {title}\")\n",
    "    print(f\"Content: {content}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n"
     ]
    }
   ],
   "source": [
    "# requests 패키지 가져오기\n",
    "import requests\n",
    "from urllib.parse import urlparse, urlencode, urlunparse\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "# 기본 URL 설정\n",
    "url = 'https://s.search.naver.com/p/newssearch/search.naver?'\n",
    "\n",
    "# 초기 파라미터 설정\n",
    "params = {\n",
    "    'field': ['0'],\n",
    "    'is_dts': ['0'],\n",
    "    'is_sug_officeid': ['0'],\n",
    "    'mynews': ['0'],\n",
    "    'nqx_theme': ['{\"theme\":{\"main\":{\"name\":\"corporation_hq\"},\"sub\":[{\"name\":\"stock\"}]}}'],\n",
    "    'office_category': ['0'],\n",
    "    'office_section_code': ['0'],\n",
    "    'office_type': ['0'],\n",
    "    'photo': ['0'],\n",
    "    'query': ['삼성전자'],\n",
    "    'service_area': ['0'],\n",
    "    'sort': '1',\n",
    "    'start': '1',\n",
    "    'where': ['news_tab_api'],\n",
    "    'ds': ['2024.05.20.00.00'],\n",
    "    'de': [datetime.now().strftime(\"%Y.%m.%d.%H.%M\")]\n",
    "}\n",
    "\n",
    "# URL 생성 함수\n",
    "def make_url(base_url, params):\n",
    "    parts = urlparse(base_url)\n",
    "    parts = parts._replace(query=urlencode(params, doseq=True))\n",
    "    return urlunparse(parts)\n",
    "\n",
    "\n",
    "\n",
    "# 수집 데이터 리스트 초기화\n",
    "total = []\n",
    "\n",
    "while True:\n",
    "    new_url = make_url(url, params)\n",
    "    response = requests.get(new_url, headers=headers)\n",
    "    soup = bs(response.content, 'html.parser')\n",
    "    naver_news_links = [a['href'] for a in soup.find_all('a', string='네이버뉴스') if a['href']]\n",
    "\n",
    "    if not naver_news_links:  # 새로운 데이터가 없을 경우 반복 중단\n",
    "        break\n",
    "\n",
    "    for link in naver_news_links:\n",
    "        tmp = {}\n",
    "        article_res = requests.get(link[2:-2])\n",
    "        article_soup = bs(article_res.content, 'html.parser')\n",
    "        title = article_soup.select_one('#title_area > span').get_text(strip=True)\n",
    "        tmp['title'] = title\n",
    "        time = article_soup.select_one('#ct > div.media_end_head.go_trans > div.media_end_head_info.nv_notrans > div.media_end_head_info_datestamp > div:nth-child(1) > span')['data-date-time']\n",
    "        tmp['date_news'] = time\n",
    "        try:\n",
    "            summary = article_soup.select_one('#dic_area > strong').get_text(strip=True)\n",
    "        except AttributeError:\n",
    "            summary = None\n",
    "        tmp['summary'] = summary\n",
    "        for tag in article_soup.find_all(class_='end_photo_org'):\n",
    "            tag.decompose()\n",
    "        main = article_soup.select_one('#dic_area').get_text(strip=True).replace(\"\\n\\n\\n\", \"\")\n",
    "        tmp['content'] = main\n",
    "        tmp['date_collect'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        tmp['url'] = link[2:-2]\n",
    "\n",
    "        total.append(tmp)\n",
    "\n",
    "    params['start'] = str(int(params['start']) + 10)\n",
    "\n",
    "print(len(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=/home/jys/.local/share/jupyter/runtime/kernel-v2-98433BgSOHawR5D8t.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from urllib.parse import urlparse, urlencode, urlunparse\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from pymongo import MongoClient\n",
    "import argparse\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"MongoDB connection parameters\")\n",
    "    parser.add_argument('--host', type=str, required=True, help='MongoDB host address') # 223.130.138.213\n",
    "    # parser.add_argument('--port', type=int, required=True, help='MongoDB port number') # 30001\n",
    "    parser.add_argument('--username', type=str, required=True, help='MongoDB username') # root\n",
    "    parser.add_argument('--password', type=str, default='financial', required=True, help='MongoDB password') # financial\n",
    "    parser.add_argument('--database', type=str, required=True, help='MongoDB database name')\n",
    "    parser.add_argument('--query', type=str, required=True, help='검색 쿼리')\n",
    "    parser.add_argument('--ds', type=str, default=datetime.now().strftime(\"%Y.%m.%d.%H\")+\".00\", help='시작 일시')\n",
    "    parser.add_argument('--de', type=str, default=datetime.now().strftime(\"%Y.%m.%d.%H.%M\"), help='종료 일시')\n",
    "    return parser.parse_args()\n",
    "\n",
    "def make_url(base_url, params):\n",
    "    parts = urlparse(base_url)\n",
    "    parts = parts._replace(query=urlencode(params, doseq=True))\n",
    "    return urlunparse(parts)\n",
    "\n",
    "def fetch_news_data(params, headers, url, db):\n",
    "    total = []\n",
    "    while True:\n",
    "        new_url = make_url(url, params)\n",
    "        response = requests.get(new_url, headers=headers)\n",
    "        soup = bs(response.content, 'html.parser')\n",
    "        naver_news_links = [a['href'] for a in soup.find_all('a', string='네이버뉴스') if a['href']]\n",
    "\n",
    "        if not naver_news_links:\n",
    "            break\n",
    "\n",
    "        batch = []\n",
    "        for link in naver_news_links:\n",
    "            article_res = requests.get(link[2:-2])\n",
    "            article_soup = bs(article_res.content, 'html.parser')\n",
    "            title = article_soup.select_one('#title_area > span').get_text(strip=True)\n",
    "            \n",
    "            press_select = article_soup.select_one('#ct > div.media_end_head.go_trans > div.media_end_head_top._LAZY_LOADING_WRAP > a > img.media_end_head_top_logo_img.light_type._LAZY_LOADING._LAZY_LOADING_INIT_HIDE')\n",
    "            press = press_select['title'] if 'title' in press_select.attrs else 'Title attribute not found'\n",
    "\n",
    "            time = article_soup.select_one('#ct > div.media_end_head.go_trans > div.media_end_head_info.nv_notrans > div.media_end_head_info_datestamp > div:nth-child(1) > span')['data-date-time']\n",
    "            summary = article_soup.select_one('#dic_area > strong').get_text(strip=True) if article_soup.select_one('#dic_area > strong') else None\n",
    "            content = article_soup.select_one('#dic_area').get_text(strip=True).replace(\"\\n\\n\\n\", \"\")\n",
    "            tmp = {\n",
    "                'date_news': time,\n",
    "                'query': params['query'],\n",
    "                'title': title,\n",
    "                'press': press,\n",
    "                'summary': summary,\n",
    "                'content': content,\n",
    "                'url': link[2:-2],\n",
    "            }\n",
    "            batch.append(tmp)\n",
    "\n",
    "        # 중복 여부 확인 및 저장\n",
    "        existing_urls = db.news.find({\"url\": {\"$in\": [news['url'] for news in batch]}}).distinct(\"url\")\n",
    "        if existing_urls:\n",
    "            batch = [news for news in batch if news['url'] not in existing_urls]\n",
    "            if not batch:\n",
    "                break\n",
    "\n",
    "        if batch:\n",
    "            db.news.insert_many(batch)\n",
    "            total.extend(batch)\n",
    "\n",
    "        params['start'] = str(int(params['start']) + 10)\n",
    "\n",
    "    return total\n",
    "\n",
    "# def update_mongodb(args, data):\n",
    "#     client = MongoClient(args.host, args.port, username=args.username, password=args.password)\n",
    "#     db = client[args.database]\n",
    "#     db.news.insert_many(data)\n",
    "\n",
    "def main():\n",
    "    args = parse_args()\n",
    "    args.host = 'mongo.stockhelper-mongodb.store'\n",
    "    args.port = ''\n",
    "    args.username = 'root'\n",
    "    args.password = 'financial'\n",
    "    args.database = 'financial'\n",
    "    args.query = '삼성전자'\n",
    "    args.ds = '2024.05.26.00.00'\n",
    "    args.de = '2024.05.26.16.52'\n",
    "\n",
    "    params = {\n",
    "        'filed': '0',\n",
    "        'is_dts': '0',\n",
    "        'is_sug_officeid': '0',\n",
    "        'nso': '&nso=so:dd,p:all,a:all',\n",
    "        'office_category': '0',\n",
    "        'office_section_code': '0',\n",
    "        'service_area': '0',\n",
    "        'query': args.query,\n",
    "        'sort': '1',\n",
    "        'start': '1',\n",
    "        'where': 'news_tab_api',\n",
    "        'nso': 'so:dd,p:all,a:all',\n",
    "        'pd': '0',\n",
    "        'ds': args.ds,\n",
    "        'de': args.de\n",
    "    }\n",
    "    url = 'https://s.search.naver.com/p/newssearch/search.naver'\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    # if args.port == '':\n",
    "    client = MongoClient(args.host, username=args.username, password=args.password)\n",
    "    # else:\n",
    "        # client = MongoClient(args.host, args.port, username=args.username, password=args.password)\n",
    "    db = client[args.database]\n",
    "    fetch_news_data(params, headers, url, db)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"https://s.search.naver.com/p/newssearch/search.naver?cluster_rank=20&de=2024.05.25&ds=2024.05.25&eid=&field=0&force_original=&is_dts=0&is_sug_officeid=0&mynews=1&news_office_checked=&nlu_query=&nqx_theme=%7B%22theme%22%3A%7B%22main%22%3A%7B%22name%22%3A%22corporation_hq%22%7D%2C%22sub%22%3A%5B%7B%22name%22%3A%22stock%22%7D%5D%7D%7D&nso=%26nso%3Dso%3Ar%2Cp%3Afrom20240525to20240525%2Ca%3Aall&nx_and_query=&nx_search_hlquery=&nx_search_query=&nx_sub_query=&office_category=0&office_section_code=0&office_type=0&pd=3&photo=0&query=%EC%82%BC%EC%84%B1%EC%A0%84%EC%9E%90&query_original=&service_area=0&sort=0&spq=0&start=11&where=news_tab_api&nso=so:r,p:from20240525to20240525,a:all&_callback=jQuery11240006142383014574593_1716901788910&_=1716901788912\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"https://search.naver.com/search.naver?where=news&query=%EC%82%BC%EC%84%B1%EC%A0%84%EC%9E%90&sm=tab_opt&sort=0&photo=0&field=0&pd=3&ds=2024.05.25&de=2024.05.25&docid=&related=0&mynews=1&office_type=0&office_section_code=0&news_office_checked=&nso=so%3Ar%2Cp%3Afrom20240525to20240525&is_sug_officeid=0&office_category=0&service_area=0\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ais",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
